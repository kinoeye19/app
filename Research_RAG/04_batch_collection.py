import os
import sys
import time
import json
import re
import requests
import pickle
import gspread
from urllib.parse import urlparse, parse_qs
from dotenv import load_dotenv
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ==========================================
# âš™ï¸ ì„¤ì • ë° ê²½ë¡œ
# ==========================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(BASE_DIR)

CLIENT_SECRET_PATH = os.path.join(PROJECT_ROOT, "mail_auto", "client_secret.json")
TOKEN_PATH = os.path.join(PROJECT_ROOT, "mail_auto", "token.json")

if not os.path.exists(CLIENT_SECRET_PATH):
    CLIENT_SECRET_PATH = os.path.join(PROJECT_ROOT, "client_secret.json")
    TOKEN_PATH = os.path.join(PROJECT_ROOT, "token.json")

SHEET_ID = os.getenv("TARGET_SHEET_ID") 
SERPER_API_KEY = os.getenv("SERPER_API_KEY")

SCOPES = [
    "https://www.googleapis.com/auth/drive",
    "https://www.googleapis.com/auth/spreadsheets"
]

# ==========================================
# ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================

def get_gspread_client():
    creds = None
    if os.path.exists(TOKEN_PATH):
        with open(TOKEN_PATH, 'rb') as token:
            try: creds = pickle.load(token)
            except: pass
            
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            if not os.path.exists(CLIENT_SECRET_PATH):
                print(f"âŒ ì¸ì¦ íŒŒì¼ ì—†ìŒ: {CLIENT_SECRET_PATH}")
                return None
            flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRET_PATH, SCOPES)
            creds = flow.run_local_server(port=0)
        with open(TOKEN_PATH, 'wb') as token:
            pickle.dump(creds, token)

    return gspread.authorize(creds)

def clean_brackets(text):
    """ê´„í˜¸()ì™€ ëŒ€ê´„í˜¸[] ë° ê·¸ ì•ˆì˜ ë‚´ìš©ì„ ì œê±°"""
    # 1. ê´„í˜¸ ë‚´ìš© ì œê±°
    cleaned = re.sub(r'\([^)]*\)', '', text)
    cleaned = re.sub(r'\[[^\]]*\]', '', cleaned)
    # 2. ë‹¤ì¤‘ ê³µë°± ì œê±°
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()
    
    # ë§Œì•½ ê´„í˜¸ ì œê±° í›„ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì•„ì§€ë©´(ì˜ˆ: ì „ì²´ê°€ ê´„í˜¸ì˜€ìŒ) ì›ë³¸ ë°˜í™˜
    if len(cleaned) < 2:
        return text
    return cleaned

def extract_main_title(title):
    """ë¶€ì œ êµ¬ë¶„ì(:, -, = ë“±) ì•ìª½ë§Œ ì¶”ì¶œ"""
    main_title = re.split(r'[:\-\=]', title)[0]
    return main_title.strip()

def get_riss_id_from_url(url):
    try:
        parsed = urlparse(url)
        qs = parse_qs(parsed.query)
        if 'control_no' in qs:
            return qs['control_no'][0]
    except:
        pass
    return ""

# ==========================================
# ğŸ” 4ë‹¨ê³„ ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ë¡œì§
# ==========================================

def search_riss_link_smart(title, author):
    url = "https://google.serper.dev/search"
    headers = {'X-API-KEY': SERPER_API_KEY, 'Content-Type': 'application/json'}

    # ê²€ìƒ‰ í›„ë³´êµ° ìƒì„±
    candidates = []
    
    # 1ë‹¨ê³„: ì›ë³¸ ì—„ê²© ê²€ìƒ‰ ("ì œëª©")
    candidates.append({"q": f'site:riss.kr "{title}" {author}', "type": "1.ì—„ê²©(ì›ë³¸)"})
    
    # 2ë‹¨ê³„: ì›ë³¸ ìœ ì—° ê²€ìƒ‰ (ì œëª© - ë”°ì˜´í‘œ ì œê±°) -> íŠ¹ìˆ˜ë¬¸ì/ë„ì–´ì“°ê¸° ë¬´ì‹œ
    candidates.append({"q": f'site:riss.kr {title} {author}', "type": "2.ìœ ì—°(ì›ë³¸)"})
    
    # 3ë‹¨ê³„: ê´„í˜¸ ì²­ì†Œ ê²€ìƒ‰ (í•œì ë³‘ê¸° ì œê±°)
    cleaned_title = clean_brackets(title)
    if cleaned_title != title:
        candidates.append({"q": f'site:riss.kr {cleaned_title} {author}', "type": "3.ìœ ì—°(ê´„í˜¸ì œê±°)"})
    
    # 4ë‹¨ê³„: ë©”ì¸ ì œëª© ê²€ìƒ‰ (ë¶€ì œ ì œê±°)
    main_title = extract_main_title(title)
    # ë©”ì¸ ì œëª©ì´ ì›ë³¸/ì²­ì†Œë³¸ê³¼ ë‹¤ë¥´ê³ , 2ê¸€ì ì´ìƒì¼ ë•Œë§Œ
    if main_title != title and main_title != cleaned_title and len(main_title) >= 2:
        candidates.append({"q": f'site:riss.kr {main_title} {author}', "type": "4.ìœ ì—°(ë¶€ì œì œê±°)"})

    # ìˆœì°¨ ì‹¤í–‰
    for item in candidates:
        query = item['q']
        q_type = item['type']
        
        # ì¿¼ë¦¬ ê¸¸ì´ ì œí•œ (Serper ì˜¤ë¥˜ ë°©ì§€)
        if len(query) > 300: query = query[:300]

        print(f"   ğŸ” ì‹œë„ [{q_type}]: {query.replace('site:riss.kr', '').strip()[:40]}...")
        
        try:
            payload = json.dumps({"q": query, "num": 3, "gl": "kr", "hl": "ko"})
            resp = requests.post(url, headers=headers, data=payload).json()
            
            for res in resp.get("organic", []):
                link = res.get("link", "")
                if "riss.kr" in link and "DetailView" in link:
                    print(f"   âœ¨ ë°œê²¬ ì„±ê³µ! ({q_type})")
                    return link
            time.sleep(0.5) # API ì†ë„ ì¡°ì ˆ
        except Exception as e:
            print(f"   âš ï¸ ê²€ìƒ‰ API ì—ëŸ¬: {e}")

    return None

def scrape_riss_details(driver, url):
    data = {"abstract": "", "keywords": "", "id": ""}
    data["id"] = get_riss_id_from_url(url)

    try:
        driver.get(url)
        wait = WebDriverWait(driver, 5)
        # ë³¸ë¬¸ ë¡œë”© ëŒ€ê¸°
        try: wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.wrapper")))
        except: pass

        # 'ë”ë³´ê¸°' ë²„íŠ¼ë“¤ í´ë¦­
        try:
            buttons = driver.find_elements(By.CSS_SELECTOR, "a.moreView, a.btn_more")
            for btn in buttons:
                if btn.is_displayed():
                    driver.execute_script("arguments[0].click();", btn)
                    time.sleep(0.1)
        except: pass
        
        full_text = driver.find_element(By.TAG_NAME, "body").text
        
        # ì´ˆë¡ ì¶”ì¶œ
        if "êµ­ë¬¸ì´ˆë¡" in full_text:
            temp = full_text.split("êµ­ë¬¸ì´ˆë¡")[1]
            data["abstract"] = temp.split("ëª©ì°¨")[0] if "ëª©ì°¨" in temp else temp[:1500]
        elif "Abstract" in full_text:
            temp = full_text.split("Abstract")[1]
            data["abstract"] = temp.split("Table of Contents")[0] if "Table of Contents" in temp else temp[:1500]
        else:
            try: data["abstract"] = driver.find_element(By.CSS_SELECTOR, "div.additionalInfo").text
            except: data["abstract"] = "ì´ˆë¡ ì—†ìŒ"

        # ì£¼ì œì–´ ì¶”ì¶œ
        try:
            lines = full_text.split('\n')
            for line in lines:
                if "ì£¼ì œì–´" in line and len(line) < 300:
                    data["keywords"] = line.replace("ì£¼ì œì–´", "").strip()
                    break
                if "Keywords" in line and len(line) < 300:
                    data["keywords"] = line.replace("Keywords", "").strip()
                    break
        except: pass

        data["abstract"] = data["abstract"].strip()
        data["keywords"] = data["keywords"].strip()

    except Exception as e:
        print(f"   âš ï¸ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")

    return data

# ==========================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰
# ==========================================
def main():
    if not SHEET_ID:
        print("âŒ ì˜¤ë¥˜: .env íŒŒì¼ì— 'TARGET_SHEET_ID'ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    client = get_gspread_client()
    if not client: return

    try:
        doc = client.open_by_key(SHEET_ID)
        worksheet = doc.worksheet("ë…¼ë¬¸")
        print(f"âœ… íƒ€ê²Ÿ ì‹œíŠ¸ ì—°ê²°: {doc.title}")
    except Exception as e:
        print(f"âŒ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
        return

    # í—¤ë” ì„¤ì •
    headers = worksheet.row_values(1)
    new_cols = ["ë…¼ë¬¸ID", "RISS_ë§í¬", "ì´ˆë¡", "ì£¼ì œì–´"]
    for col_name in new_cols:
        if col_name not in headers:
            worksheet.update_cell(1, len(headers) + 1, col_name)
            headers.append(col_name)

    idx_id = headers.index("ë…¼ë¬¸ID") + 1
    idx_link = headers.index("RISS_ë§í¬") + 1
    idx_abs = headers.index("ì´ˆë¡") + 1
    idx_kw = headers.index("ì£¼ì œì–´") + 1

    rows = worksheet.get_all_records()
    print(f"ğŸ“Š ì´ {len(rows)}ê±´ ì‘ì—… ì‹œì‘...\n")

    # ë¸Œë¼ìš°ì € ì˜µì…˜
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)

    for i, row in enumerate(rows):
        row_num = i + 2
        
        title = str(row.get("ë…¼ë¬¸ëª…", "")).strip()
        author = str(row.get("ì´ë¦„", "")).strip()
        existing_link = str(row.get("RISS_ë§í¬", ""))

        # ì´ë¯¸ ë§í¬ê°€ ìˆìœ¼ë©´ ê±´ë„ˆëœ€ (ë‹¨, 'ê²€ìƒ‰ì‹¤íŒ¨'ë¼ê³  ì íŒ ê±´ ë‹¤ì‹œ ì‹œë„)
        if title and existing_link and "http" in existing_link:
            continue
        if not title:
            continue

        print(f"[{i+1}/{len(rows)}] ğŸ” {title} ({author})")
        
        # ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ ì‹¤í–‰
        link = search_riss_link_smart(title, author)
        
        if link:
            details = scrape_riss_details(driver, link)
            print(f"   âœ… ìˆ˜ì§‘ ì™„ë£Œ: ID({details['id']}) / í‚¤ì›Œë“œ({details['keywords'][:10]}...)")
            
            try:
                worksheet.update_cell(row_num, idx_id, details['id'])
                worksheet.update_cell(row_num, idx_link, link)
                worksheet.update_cell(row_num, idx_abs, details['abstract'][:4000])
                worksheet.update_cell(row_num, idx_kw, details['keywords'])
            except Exception as e:
                print(f"   âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
        else:
            print("   âš ï¸ ëª¨ë“  ê²€ìƒ‰ ì‹œë„ ì‹¤íŒ¨")
            # í™•ì‹¤íˆ ì‹¤íŒ¨í–ˆì„ ë•Œë§Œ ê¸°ë¡
            if not existing_link:
                try: worksheet.update_cell(row_num, idx_link, "ê²€ìƒ‰ì‹¤íŒ¨")
                except: pass
            
        time.sleep(2) # ì°¨ë‹¨ ë°©ì§€

    driver.quit()
    print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")

if __name__ == "__main__":
    main()